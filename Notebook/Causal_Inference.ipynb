{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c25669c1-e0f3-437c-8517-ccab8534b8b0",
   "metadata": {},
   "source": [
    "## Theoretical heart of causal inference\n",
    "**1. What Is a Causal Graph?**\n",
    "- A Causal Graph (or Directed Acyclic Graph, DAG) is a visual and mathematical representation of causal relationships between variables.\n",
    "- Nodes (V): Variables in your system (e.g., Smoking, Cancer).\n",
    "- Directed Edges (â†’): Causal effects (e.g., Smoking â†’ Cancer).\n",
    "- Acyclic: No feedback loops (no circular causation).\n",
    "\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Smoking â”€â”€â”€â–¶ Tar buildup â”€â”€â”€â–¶ Lung Cancer <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Lung Cancer\n",
    "\n",
    "This diagram encodes causal structure, not just correlations.\n",
    "\n",
    "**2. From Correlation to Causation**\n",
    "- Traditional statistics estimates ğ‘ƒ(ğ‘Œâˆ£ğ‘‹)\n",
    "P(Yâˆ£X): â€œGiven that we observe X, whatâ€™s Y?â€\n",
    "- Causal inference wants ğ‘ƒ(ğ‘Œâˆ£ğ‘‘ğ‘œ(ğ‘‹))\n",
    "P(Yâˆ£do(X)): â€œIf we force X to a value, whatâ€™s Y?â€\n",
    "\n",
    "That do(X) operator is crucial â€” it represents intervention, not observation.\n",
    "The goal of causal analysis is to express ğ‘ƒ(ğ‘Œâˆ£ğ‘‘ğ‘œ(ğ‘‹))\n",
    "P(Yâˆ£do(X)) in terms of observable quantities (plain probabilities) whenever possible.\n",
    "\n",
    "**3. The do-Operator**\n",
    "- The do-operator, introduced by Judea Pearl, expresses interventions:\n",
    "$$\n",
    "P(Yâˆ£do(X=x))\n",
    "$$\n",
    "- means: â€œSet X to x externally (like a randomized experiment) and observe the resulting distribution of Y.â€\n",
    "- Mathematically, this means `removing all incoming edges into X` in the causal graph (since weâ€™ve broken the natural causes of X).\n",
    "\n",
    "**4. Backdoor Paths and Confounding**\n",
    "- A `backdoor path` is a non-causal path from X to Y that starts with an arrow into X â€” usually through a confounder. <br>\n",
    "U (genetics) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; â†™ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; â†˜ <br>\n",
    "X (smoking) â†’ Y (cancer)\n",
    "\n",
    "Here, U is a confounder because it affects both X and Y.\n",
    "To estimate ğ‘ƒ(ğ‘Œâˆ£ğ‘‘ğ‘œ(ğ‘‹))\n",
    "P(Yâˆ£do(X)), you must â€œblockâ€ that backdoor path by `conditioning on U`.\n",
    "\n",
    "**Backdoor Criterion**\n",
    "A set of variables Z satisfies the backdoor criterion if:\n",
    "- Z blocks every backdoor path between X and Y, and\n",
    "- Z does not include descendants of X.\n",
    "\n",
    "Then:\n",
    "$$\n",
    "P(Yâˆ£do(X))= \\sum_z P(Y|X,Z)P(Z)\n",
    "$$\n",
    "This is the backdoor adjustment formula.\n",
    "\n",
    "**5. The Three Rules of Do-Calculus**\n",
    "- Do-calculus provides a `formal algebra` for manipulating expressions involving do().\n",
    "It defines when interventions can be replaced with observations.\n",
    "\n",
    "**Rule 1 â€” Insertion/deletion of observations**<br>\n",
    "If Y â«« Z | X, W in the graph where edges into X are removed,<br>\n",
    "then:\n",
    "$$\n",
    "P(Yâˆ£do(X),Z,W)=P(Yâˆ£do(X),W)\n",
    "$$\n",
    "Interpretation: If Z gives no new info about Y after conditioning on X and W, drop Z.\n",
    "\n",
    "**Rule 2 â€” Action/observation exchange**<br>\n",
    "If Y â«« Z | X, W in the graph where edges out of Z are removed,<br>\n",
    "then:\n",
    "$$\n",
    "P(Yâˆ£do(X),do(Z),W)=P(Yâˆ£do(X),Z,W)\n",
    "$$\n",
    "Interpretation: If Zâ€™s effect on Y is blocked by X and W, treat Z as observed instead of intervened.\n",
    "\n",
    "**Rule 3 â€” Insertion/deletion of actions**<br>\n",
    "If Y â«« Z | X, W in the graph where edges into X and out of Z are removed, <br>\n",
    "then:\n",
    "$$\n",
    "P(Yâˆ£do(X),do(Z),W)=P(Yâˆ£do(X),W)\n",
    "$$\n",
    "Interpretation: If intervening on Z doesnâ€™t affect Y given X and W, drop that intervention.\n",
    "\n",
    "**6. Putting It Together â€” Identification**<br>\n",
    "The `goal of causal identification` is to express ğ‘ƒ(ğ‘Œâˆ£ğ‘‘ğ‘œ(ğ‘‹)) entirely in terms of observable probabilities <br>\n",
    "P(Yâˆ£X,Z) and ğ‘ƒ(ğ‘)P(Z). <br>\n",
    "If we can do that, the effect is `identifiable`.\n",
    "\n",
    "Example (Backdoor Adjustment): <br>\n",
    "\n",
    "X â† Z â†’ Y\n",
    "\n",
    "Here, Z is a confounder. <br>\n",
    "Then:\n",
    "$$\n",
    "P(Yâˆ£do(X))=\\sum_z P(Yâˆ£X,z)P(z)\n",
    "$$\n",
    "\n",
    "**7. Frontdoor Adjustment**<br>\n",
    "When you canâ€™t block confounding directly, sometimes an `intermediate mediator` helps: <br>\n",
    "X â†’ M â†’ Y <br>\n",
    "â†‘ <br>\n",
    "U â†’ Y <br>\n",
    "\n",
    "If:\n",
    "- M intercepts all directed paths from X to Y, and\n",
    "- U doesnâ€™t directly affect M,\n",
    "\n",
    "then:\n",
    "$$\n",
    "P(Yâˆ£do(X))=\\sum_m P(Mâˆ£X) \\sum_{x'} P(Yâˆ£M,X')P(X')\n",
    "$$\n",
    "This is the `frontdoor` adjustment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Causal",
   "language": "python",
   "name": "causal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
